#!/bin/bash
run_folder="$PWD"

# Create a time stamp, in order to make backups
datetime=$(date "+%Y%m%d%H%M%S")

# Time format
TIMEFORMAT='Execution time : %1lR'

# Start up
source $CHEMFLOW_HOME/ScoreFlow/ScoreFlow_interface.bash
source $CHEMFLOW_HOME/ScoreFlow/ScoreFlow_functions.bash
source $CHEMFLOW_HOME/common/mazinger_functions.bash
source $CHEMFLOW_HOME/common/ProgressBar.bash
source $CHEMFLOW_HOME/common/ChemFlow_functions.bash

# Welcome user
welcome

# Source ChemFlow config file for paths
source $CHEMFLOW_HOME/ChemFlow.config

# User interface
SF_CLI "$@"

# Write user parameters to a temporary file
print_vars > temp.config

# if config file specified using the -f flag
if [ ! -z "$CONFIG_FILE" ]; then
  echo "Reading configuration from $CONFIG_FILE"
  source "$CONFIG_FILE"
else
# if a config file was not specified
  # if a config file exists in the current directory
  if [ -f ScoreFlow.config ]; then
    # Use this one instead
    source ScoreFlow.config
  # if no config file was specified and doesn't exist in the current directory
  else
    echo "${RED}FATAL ERROR${NC} : No configuration file found for ScoreFlow"
    usage
    exit 1
  fi
fi
# Overwrite parameters in config files with user parameters
write_SF_config

# Empty the input_files/com directory for new MD or 1F simulations
if [ "${purge}" = "true" ]; then
  rm -rf ${run_folder}/input_files/com
fi

# Check input file and make list of poses to rescore
prepare_rescoring

# Identify which program to use, and run it
if $(list_include_item "chemplp plp plp95" "${scoring_function}"); then
  rescore_method="plants"
  time run_plants
  # Concatenate final results, serial instead of parallel
  cat ${run_folder}/rescoring/${scoring_function}/ranking/*.csv >> ${run_folder}/rescoring/${scoring_function}/ranking.csv
  cat ${run_folder}/rescoring/${scoring_function}/features/*.csv >> ${run_folder}/rescoring/${scoring_function}/features.csv
  rm -rf ${run_folder}/rescoring/${scoring_function}/{ranking,features}/

elif [ "${scoring_function}" == "vina" ]; then
  rescore_method="vina"
  time run_vina
  # Concatenate final results, serial instead of parallel
  cat ${run_folder}/rescoring/${scoring_function}/ranking/*.csv >> ${run_folder}/rescoring/${scoring_function}/ranking.csv
  rm -rf ${run_folder}/rescoring/${scoring_function}/{ranking}/

elif $(list_include_item "PB3 GB5 GB8" "${scoring_function}"); then
  rescore_method="mmpbsa"
  time run_mmpbsa
  # Concatenate final results, serial instead of parallel
  for result in 1F_min MD_min MD_prod ranking; do
    if [ -d ${run_folder}/rescoring/${scoring_function}/${result} ]; then
      cat ${run_folder}/rescoring/${scoring_function}/${result}/*.csv >> ${run_folder}/rescoring/${scoring_function}/${result}.csv
      rm -rf ${run_folder}/rescoring/${scoring_function}/${result}/
    fi
  done
fi

# At this point, calculations should be done

# copy config file to output folder
cp ${run_folder}/ScoreFlow.config ${run_folder}/rescoring/${scoring_function}/

# Remove empty directories
cd ${run_folder}/rescoring/${scoring_function}/
rmdir --ignore-fail-on-non-empty * &> /dev/null
cd ${run_folder}

# If some results are missing, count how many and output it
if [ -f rescoring/${scoring_function}/errors.csv ]; then
  errorcount=$(cat rescoring/${scoring_function}/errors.csv | wc -l)
  echo -e "${RED}ERRORS detected${NC} : ${errorcount}"
  echo "See rescoring/${scoring_function}/errors.csv for more info"
fi

# Exit
exit_message
